diff --git a/user/inc/cond_type.h b/user/inc/cond_type.h
index e69bb39..450918c 100644
--- a/user/inc/cond_type.h
+++ b/user/inc/cond_type.h
@@ -6,12 +6,12 @@
 #ifndef _COND_TYPE_H
 #define _COND_TYPE_H
 
-#include <mutex.h>
 #include <cllist.h>
+#include <spin.h>
 
 
 typedef struct cond {
-	mutex_t	mutex;
+	spin_s lock;
 	cll_list queue;
 } cond_t;
 
diff --git a/user/inc/rwlock_type.h b/user/inc/rwlock_type.h
index f8d08d3..646b1fc 100644
--- a/user/inc/rwlock_type.h
+++ b/user/inc/rwlock_type.h
@@ -23,7 +23,7 @@ typedef struct rwlock {
   cll_list readers_reading;
   cll_list readers_waiting;
   int state;
-  node_t writer; /* Writer holding lock. Make sure they are the one
+  int writer_tid; /* Writer holding lock. Make sure they are the one
                     who relinquishes it */
 } rwlock_t;
 
diff --git a/user/libthread/synch/cvar.c b/user/libthread/synch/cvar.c
index f8e87bc..5fcf8c7 100644
--- a/user/libthread/synch/cvar.c
+++ b/user/libthread/synch/cvar.c
@@ -1,8 +1,11 @@
 /** @file cvar.c
  *
- *  TODO: comment here.
+ *  @brief This file implements our condition variables.
  *
  *  @author Marlies Ruck (mruck)
+ *  @author Enrique Naudon (esn)
+ *
+ *  @bug Change mutexes to spin locks and tcb to queue entry 
  **/
 
 #include "qentry.h"
@@ -10,6 +13,7 @@
 #include <cond.h>
 
 #include <assert.h>
+#include <spin.h>
 #include <mutex.h>
 #include <syscall.h>
 #include <thread.h>
@@ -31,106 +35,128 @@ int cond_init(cond_t *cv)
 {
   if(cv == NULL) return -1;
 
-  mutex_init(&cv->mutex);
+  spin_init(&cv->lock);
   cll_init_list(&cv->queue);
 
   return 0;
 }
-
+/* @brief "deactive" cond var
+ *
+ * It is illegal for an application to use a condition variable after it has
+ * been destroyed(unless and until it is later re-initialized).  It is illegal
+ * for an application to invoke cond_destroy() on a condition variable while
+ * threads are blocked waiting on it.
+ *
+ * @param cv Cond var to destroy
+ */
 void cond_destroy(cond_t *cv)
 {
-  if(cv == NULL) return;
+  assert(cv);
+  assert(cll_empty(&cv->queue));
   return;
 }
 
 /* @brief Allows a thread to wait for a condition and release the associated
- *        mutex that it needs to hold to check that condition 
+ * mutex that it needs to hold to check that condition 
  *        
- *        The calling thread blocks, waiting to be signaled.  The blocked thread
- *        may be awakended by a cond_signal() or cond_broadcast().  
+ * The calling thread blocks, waiting to be signaled.  The blocked thread
+ * may be awakended by a cond_signal() or cond_broadcast().  
  *
- *    Statically allocate a cll_node to add to the queue of threads waiting
- *    to be signaled.  This struct can be statically allocated because the
- *    thread is de-scheduled while waiting to be signaled so its stack will
- *    remain intact.
+ * Statically allocate a cll_node to add to the queue of threads waiting to
+ * be signaled.  This struct can be statically allocated because the thread
+ * is de-scheduled while waiting to be signaled so its stack will remain
+ * intact.
  *
- *        @param *cv Condition variable 
- *        @param *mp Mutex needed to hold to check the condition.  Upon return
- *                from cond_wait() *mp had been re-acquired on behalf of the 
- *                calling thread
- * 
+ * @param *cv Condition variable 
+ * @param *mp Mutex needed to hold to check the condition.  Upon return from 
+ * cond_wait() *mp had been re-acquired on behalf of the calling thread
  */
-void cond_wait(cond_t *cv, mutex_t *mp){
+void cond_wait(cond_t *cv, mutex_t *mp)
+{
   qentry_s qe;
   cll_node n;
 
-  if((cv == NULL) || (mp == NULL)) return;
+  assert(cv);
+  assert(mp);
 
-  /* TODO: replace this with your real TCB */
   qe.tid = gettid();
 
   /* lock cvar mutex and atomically enqueue */
   cll_init_node(&n,&qe);
-  mutex_lock(&(cv->mutex));
-  cll_insert(&(cv->queue) ,&n);
+  spin_lock(&cv->lock);
+  cll_insert(&cv->queue,&n);
 
   /* Release world mutex */
   mutex_unlock(mp);
 
   /* Unlock and deschedule */
   qe.reject = 0;
-  mutex_unlock(&(cv->mutex));
+  spin_unlock(&cv->lock);
   while (qe.reject == 0)
     deschedule(&(qe.reject));
 
   /* Lock world mutex and make progress */
   mutex_lock(mp);
+  return;
 }
-
-void cond_signal(cond_t *cv) {
+/* @brief Wake up a thread waiting on the condition variable
+ *
+ * @param cv Condition variable with queue of threads to awaken
+ */
+void cond_signal(cond_t *cv) 
+{
   cll_node *n;
   qentry_s *qe;
 
-  if(cv == NULL) return;
+  assert(cv);
 
-  mutex_lock(&(cv->mutex));
+  /* Atomically access condition variable */
+  spin_lock(&cv->lock);
 
   /* If someone is in the queue, signal them */
   if (!cll_empty(&cv->queue)) {
-    n = cll_extract(&(cv->queue), cv->queue.next);
+    n = cll_extract(&cv->queue, cv->queue.next);
     qe = cll_entry(qentry_s *, n);
 
     /* Unlock and wake */
     int tid = qe->tid;
-    mutex_unlock(&(cv->mutex));
+    spin_unlock(&cv->lock);
     qe->reject = 1; 
     make_runnable(tid);
   }
 
   /* Otherwise, just unlock */
-  else mutex_unlock(&(cv->mutex));
+  else spin_unlock(&cv->lock);
 
   return;
 }
 
-void cond_broadcast(cond_t *cv) {
+/* @brief Wake up all threads waiting on the condition variable
+ *
+ * Note: cond_broadcast() does not awaken threads which may invoke cond_wait(cv)
+ * "after" this call to cond_broadcast() has begun.
+ *
+ * @param cv Wake up threads waiting on condition variable pointed to be cv
+ */
+void cond_broadcast(cond_t *cv) 
+{
   cll_node *n;
   qentry_s *qe;
 
-  if(cv == NULL) return;
+  assert(cv);
 
-  mutex_lock(&(cv->mutex));
+  spin_lock(&cv->lock);
 
   /* if someone is in the queue signal them */
   while (!cll_empty(&cv->queue)) {
-    n = cll_extract(&(cv->queue), cv->queue.next);
+    n = cll_extract(&cv->queue, cv->queue.next);
     qe = cll_entry(qentry_s *, n);
 
     qe->reject = 1; 
     make_runnable(qe->tid);
   }
 
-  mutex_unlock(&(cv->mutex));
+  spin_unlock(&cv->lock);
   return;
 }
 
diff --git a/user/libthread/synch/mutex.c b/user/libthread/synch/mutex.c
index 42528d0..f63302e 100644
--- a/user/libthread/synch/mutex.c
+++ b/user/libthread/synch/mutex.c
@@ -42,6 +42,8 @@
  **/
 int mutex_init(mutex_t *mp)
 {
+  if(mp == NULL) return -1;
+
   spin_init(&mp->lock);
   mp->state = MUTEX_UNLOCKED;
   mp->owner = -1;
@@ -59,6 +61,7 @@ int mutex_init(mutex_t *mp)
  **/
 void mutex_destroy(mutex_t *mp)
 {
+  assert(mp);
   assert(queue_empty(&mp->queue));
   assert(mp->state != MUTEX_LOCKED);
   return;
@@ -79,6 +82,8 @@ void mutex_lock(mutex_t *mp)
   queue_node_s n;
   qentry_s qe;
 
+  assert(mp);
+
   /* Wait your turn to access the waiting list */
   spin_lock(&mp->lock);
 
@@ -121,6 +126,8 @@ void mutex_unlock(mutex_t *mp)
   qentry_s *qe;
   int tid;
 
+  assert(mp);
+
   /* Wait your turn to access the waiting list */
   spin_lock(&mp->lock);
 
diff --git a/user/libthread/synch/rwlock.c b/user/libthread/synch/rwlock.c
index 732ce57..2ffc7bc 100644
--- a/user/libthread/synch/rwlock.c
+++ b/user/libthread/synch/rwlock.c
@@ -8,10 +8,11 @@
 #include <thr_data.h>
 #include <syscall.h>
 #include <thread.h>
+#include <malloc.h>
 
 /* Helper routines */
 void broadcast_readers(rwlock_t *rwlock);
-void init_node(node_t *data, cll_node *n);
+cll_node *init_node(void);
 void read_lock(rwlock_t *rwlock);
 void write_lock(rwlock_t *rwlock);
 int read_unlock(rwlock_t *rwlock);
@@ -47,12 +48,14 @@ void rwlock_lock(rwlock_t *rwlock, int type){
   if(rwlock == NULL) 
        return;
   spin_lock(&rwlock->lock);
+  lprintf("acquired rwlock_lock spin lock");
   switch(type){
     case RWLOCK_READ:
       read_lock(rwlock);
       break;
     case RWLOCK_WRITE:
       write_lock(rwlock);
+      spin_unlock(&rwlock->lock);
       break;
     default:
       break;
@@ -71,18 +74,11 @@ void rwlock_lock(rwlock_t *rwlock, int type){
  */
 void rwlock_unlock(rwlock_t *rwlock) 
 {
-  if(rwlock == NULL)
-    return;
+  assert(rwlock != NULL);
 
+  lprintf("locking rw unlock...");
   spin_lock(&rwlock->lock);
-
-  /* No one is waiting */
-  if((cll_empty(&rwlock->readers_reading)) && (cll_empty(&rwlock->writers)) &&
-      (cll_empty(&rwlock->readers_waiting))){
-      rwlock->state = UNLOCKED;
-      spin_unlock(&rwlock->lock);/* @Bug Should we zero out old writer node? */
-      return;
-  }
+  lprintf("locked spin lock");
 
   /* Validate that thread is in critical section */
   int retval;
@@ -90,12 +86,15 @@ void rwlock_unlock(rwlock_t *rwlock)
     case RWLOCK_READ:
       /* Reader is not currently in critical section or there are still readers
        * in the critical section even after this thread leaves */
+      lprintf("unlock read lock");
       if(0 > (retval = read_unlock(rwlock)))
         return;
       break; 
     case RWLOCK_WRITE:
+      lprintf("unlock write lock");
       /* Ensure the writer calling unlock holds the lock */
-      if(gettid() != rwlock->writer.tid){
+      if(gettid() != rwlock->writer_tid){
+          lprintf("gettid() != writer_tid");
           spin_unlock(&rwlock->lock);
           return;
       }
@@ -105,6 +104,7 @@ void rwlock_unlock(rwlock_t *rwlock)
   }
 
   /* The lock is now free.  Let someone else in the critical section */
+  lprintf("calling update_rwlock()");
   update_rwlock(rwlock);
   return;
 }
@@ -113,15 +113,16 @@ void rwlock_downgrade(rwlock_t *rwlock)
   if(rwlock == NULL) 
     return;
   spin_lock(&rwlock->lock);
-  if((rwlock->state == RWLOCK_WRITE) && (rwlock->writer.tid == thr_getid())){
+  if((rwlock->state == RWLOCK_WRITE) && (rwlock->writer_tid == thr_getid())){
+    /* update state */
+    rwlock->state = RWLOCK_READ;
+
     /* Wake up all readers */
     broadcast_readers(rwlock);
 
     /* Add downgraded reader to the list of readers in the critical section */
-    cll_node n;
-    init_node(&rwlock->writer,&n);
-
-    cll_insert(&rwlock->readers_reading, &n);
+    cll_node *n = init_node();
+    cll_insert(&rwlock->readers_reading, n);
   }
   spin_unlock(&rwlock->lock);
   return;
@@ -134,25 +135,32 @@ void rwlock_downgrade(rwlock_t *rwlock)
  * Assumes queue is locked before being called 
  */
 void broadcast_readers(rwlock_t *rwlock){
-  while(!(cll_empty(&rwlock->readers_waiting))){
-    cll_node *head = cll_extract(&rwlock->readers_waiting,rwlock->readers_waiting.next);
-    node_t *reader = cll_entry(node_t *, head);
+  cll_node *n;
+  cll_foreach(&rwlock->readers_reading,n){
+    node_t *reader = cll_entry(node_t *, n);
     reader->reject = thr_getid();
     make_runnable(reader->tid);
   }
-  /* Reset count and state */
-  rwlock->state = RWLOCK_READ;
+
+  /* Lists of readers in critical section is now list of old readers waiting */
   rwlock->readers_reading = rwlock->readers_waiting;
+
+  /* Reset state */
+  rwlock->state = RWLOCK_READ;
+
   /* Re-initalize list of readers waiting */
   cll_init_list(&rwlock->readers_waiting);
 
   return;
 }
 
-void init_node(node_t *data, cll_node *n){
+cll_node *init_node(void){
+  node_t *data = malloc(sizeof(node_t));
+  cll_node *n = malloc(sizeof(cll_node));
   data->tid = thr_getid();
   data->reject = 0;
   cll_init_node(n, data);
+  return n;
 }
 /* @Brief Allow readers to enter critical section or enqueue
  *
@@ -160,8 +168,9 @@ void init_node(node_t *data, cll_node *n){
  */
 void read_lock(rwlock_t *rwlock)
 {
-  node_t data;
-  cll_node n;
+  cll_node *n = init_node();
+  node_t *data = cll_entry(node_t *, n);
+  lprintf("read_lock()");
 
   switch(rwlock->state){
     case UNLOCKED:
@@ -172,19 +181,20 @@ void read_lock(rwlock_t *rwlock)
        * section. */
       if(cll_empty(&rwlock->writers)){
         /* Add yourself to the list of readers in the critical section */
-        init_node(&data,&n);
-        cll_insert(&rwlock->readers_reading,&n);
+        cll_insert(&rwlock->readers_reading,n);
         /* Relinquish lock */
         spin_unlock(&rwlock->lock);
         break;
       }
     /* Writers are waiting/writing, fall through and enqueue yourself */
     case RWLOCK_WRITE:
-      init_node(&data,&n);
-      cll_insert(&rwlock->readers_waiting,&n);
+      cll_insert(&rwlock->readers_waiting,n);
+      lprintf("relinquishing lock...");
       spin_unlock(&rwlock->lock);
-      do deschedule(&data.reject);
-      while (data.reject == 0);
+      lprintf("relinquished lock...");
+      do deschedule(&data->reject);
+      while (data->reject == 0);
+      lprintf("reader awakened");
       break;
     default:
       break;
@@ -196,23 +206,22 @@ void read_lock(rwlock_t *rwlock)
  */
 void write_lock(rwlock_t *rwlock)
 {
-  node_t data;
-  cll_node n;
   /* Initalize a node for the writer */
-  init_node(&data,&n);
+  cll_node *n = init_node();
+  node_t *data = cll_entry(node_t *, n);
   /* Lock is free.  Take it. */
   if(rwlock->state == UNLOCKED){
     rwlock->state = RWLOCK_WRITE;
-    rwlock->writer = data;
+    rwlock->writer_tid = gettid();
     spin_unlock(&rwlock->lock);
   }
   /* A reader or writer currently holds the lock.  Enqueue yourself */
   else{
     /* Add yourself to the queue */
-    cll_insert(&rwlock->writers,&n);
+    cll_insert(&rwlock->writers,n);
     spin_unlock(&rwlock->lock);
-    do deschedule(&data.reject);
-    while (data.reject == 0);
+    do deschedule(&data->reject);
+    while (data->reject == 0);
   }
 }
 /* Assumes: rwlock is locked before call 
@@ -223,20 +232,31 @@ int read_unlock(rwlock_t *rwlock)
    * list of readers in the critical section */
   cll_node *n;
   node_t *data;
+  lprintf("in read unlock");
   cll_foreach(&rwlock->readers_reading,n){
     data = cll_entry(node_t *,n);
-    if(data->tid == gettid())
-      break;
+    if(data != NULL){
+      if(data->tid == gettid())
+        break;
+    }
   }
+  lprintf("cll_foreach");
   /* We traversed the entire list and didn't find the tid.  This thread is
   * not in the critical section */
   if(n == (cll_node*)(&rwlock->readers_reading)){
     spin_unlock(&rwlock->lock);
     return -1;
   }
+  lprintf("node found, remove from list");
   /* Otherwise remove the reader from the list of readers in the critical
   * section */
-  cll_extract(&rwlock->readers_reading, n);
+  n = cll_extract(&rwlock->readers_reading, n);
+  data = cll_entry(node_t *,n);
+  /* Free the reader */
+  free(data);
+  free(n);
+  
+  lprintf("node extracted");
 
   /* There are still readers in the critical section */
   if(!cll_empty(&rwlock->readers_reading)){
@@ -250,23 +270,33 @@ int read_unlock(rwlock_t *rwlock)
  */
 void update_rwlock(rwlock_t *rwlock)
 {
+  lprintf("updating lock");
   /* No new reader can acquire a shared lock if a writer is waiting */
   if(!(cll_empty(&rwlock->writers))){
     cll_node *head = cll_extract(&rwlock->writers,rwlock->writers.next);
     node_t *writer = cll_entry(node_t *, head);
     /* update owner and state */
-    rwlock->writer = *writer;
+    rwlock->writer_tid = writer->tid;
     rwlock->state = RWLOCK_WRITE;
     /* Don't be selfish. Let someone else join the queue */
     spin_unlock(&rwlock->lock);
     /* Wake up the writer */
     writer->reject = thr_getid();
     make_runnable(writer->tid);
+    /* Free writer */
+    free(writer);
+    free(head);
     }
   /* No writers are waiting, wake up the readers */
-  else{
+  else if (!(cll_empty(&rwlock->readers_waiting))){
     broadcast_readers(rwlock);
     spin_unlock(&rwlock->lock);
   }
+  /* No one is waiting */
+  else{
+      rwlock->state = UNLOCKED;
+      spin_unlock(&rwlock->lock);/* @Bug Should we zero out old writer node? */
+      return;
+  }
   return;
 }
diff --git a/user/libthread/synch/sem.c b/user/libthread/synch/sem.c
index f17b8f9..20ab555 100644
--- a/user/libthread/synch/sem.c
+++ b/user/libthread/synch/sem.c
@@ -1,8 +1,11 @@
 /** @file sem.c
  *
- *  TODO: comment here.
- *
+ *  @brief This file implements semaphores.
+ * 
  *  @author Marlies Ruck (mruck)
+ *  @author Enrique Naudon (esn)
+ *
+ *  @bug No known bugs
  **/
 
 #include "qentry.h"
@@ -16,7 +19,14 @@
 #include <syscall.h>
 #include <thread.h>
 
-int sem_init(sem_t *sem, int count){
+/* @brief Initialize semaphore
+ *
+ * @param sem Semaphore to be initialized
+ * @param count Value to be initalized to 
+ * @return -1 if cv is invalid(NULL) or count < 0 else 0 on success
+ */
+int sem_init(sem_t *sem, int count)
+{
   if((sem == NULL) || (count < 0))
     return -1;
 
@@ -27,21 +37,34 @@ int sem_init(sem_t *sem, int count){
 
   return 0;
 }
-void sem_destroy(sem_t *sem){
-  if(sem == NULL)
-    return;
-  assert(cll_empty(&sem->queue)); /* perhaps redundant? */
+/* @brief "deactivate" semaphore
+ *
+ * Effects of using a semaphore before it has been initalized are undefined.  
+ * It is illegal for an application to use a sempahore after it has been
+ * destroyed (unless and until it is later re-initialized).  It is illegal for
+ * an application to invoke sem_destroy() on a semphaore while threads are
+ * waiting on it.
+ *
+ * @param sem Semaphore to destroy
+ */
+void sem_destroy(sem_t *sem)
+{
+  assert(sem);
+  assert(cll_empty(&sem->queue)); 
 }
-void sem_wait(sem_t *sem){
-  if(sem == NULL)
-    return;
+/* @brief Allows thread to decrement semaphore value, and may cause it to block
+ * indefinitely until it is legal to perform the decrement
+ *
+ * @param sem Semaphore to decrement
+ */
+void sem_wait(sem_t *sem)
+{
+  assert(sem);
 
   /* Wait your turn to access the global count */
   spin_lock(&sem->lock);
 
   if(sem->count > 0){
-    /* For debugging purposes */
-    assert(cll_empty(&sem->queue)); 
     --(sem->count);
     spin_unlock(&sem->lock);
   }
@@ -50,7 +73,7 @@ void sem_wait(sem_t *sem){
     qentry_s qe;
 
     /* Enqueue yourself */
-    qe.tid = thr_getid();
+    qe.tid = gettid();
     cll_init_node(&n, &qe);
     cll_insert(&sem->queue, &n);
 
@@ -64,10 +87,13 @@ void sem_wait(sem_t *sem){
     cll_final_node(&n);
   }
 }
-
-void sem_signal(sem_t *sem){
-  if(sem == NULL)
-    return;
+/* @brief Wake up a thread waiting on the semaphore
+ *
+ * @param sem semaphore thread is waiting on
+ */
+void sem_signal(sem_t *sem)
+{
+  assert(sem);
 
   /* Wait your turn to access the global count */
   spin_lock(&sem->lock);
@@ -80,7 +106,7 @@ void sem_signal(sem_t *sem){
     /* Unlock and make runnable head */
     int tid = qe->tid;
     spin_unlock(&sem->lock);
-    qe->reject = thr_getid();
+    qe->reject = gettid();
     make_runnable(tid);
   }
   else {
diff --git a/user/progs/rwlock.c b/user/progs/rwlock.c
new file mode 100644
index 0000000..cd87acc
--- /dev/null
+++ b/user/progs/rwlock.c
@@ -0,0 +1,62 @@
+#include <rwlock.h>
+#include <simics.h>
+#include <thread.h>
+#include <syscall.h>
+#include <stdio.h>
+#include <string.h>
+
+#define NUM_ELEM 4
+#define BUF_SIZE 256
+#define NUM_THREADS 8
+
+char buf[BUF_SIZE];
+unsigned int offset = 0;
+
+char *array[] = {"summer","spring","frolic","play"};
+int tid[NUM_THREADS];
+
+rwlock_t lock;
+
+void *reader(void *param){
+  while(buf == NULL)
+    yield(-1);
+  lprintf("reader locking...");
+  rwlock_lock(&lock, RWLOCK_READ);
+  lprintf("reader %d reads: %s",gettid(),buf);
+  rwlock_unlock(&lock);
+  lprintf("read released lock");
+  return NULL;
+}
+void *writer(void *param){
+  int i = (int)(param);
+  lprintf("writer locking...");
+  rwlock_lock(&lock, RWLOCK_WRITE);
+  lprintf("writer locked");
+  char *pos = (char *)((unsigned)(buf) + offset);
+  sprintf(pos,"%s",array[i]);
+  offset+= strlen(array[i]);
+  lprintf("writer unlocking...");
+  rwlock_unlock(&lock);
+  lprintf("writer unlocked");
+  return NULL;
+}
+int main(){
+  thr_init(PAGE_SIZE);
+  rwlock_init(&lock);
+
+  int t = 0;
+  /* Spawn readers */
+  //for(t = 0; t < NUM_ELEM; ++t){
+  //}
+  //for(t = 4; t < NUM_THREADS; ++t){
+    tid[t] = thr_create(writer, (void *)(0));
+    lprintf("spawned writer");
+    t++;
+    tid[t] = thr_create(reader,NULL);
+    lprintf("spawned reader");
+    //yield(tid[t-NUM_ELEM]);
+  //}
+  for(t = 0; t < 2 ; ++t)
+    thr_join(tid[t],NULL);
+  return 0;
+}
